{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fbdda79",
   "metadata": {},
   "source": [
    "\n",
    "Authors: Simon Vandenhende\n",
    "Licensed under the CC BY-NC 4.0 license (https://creativecommons.org/licenses/by-nc/4.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install easydict\n",
    "\n",
    "!pip install imageio\n",
    "!pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af7e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch_tensorrt\n",
    "import torchvision.transforms\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.config import create_config\n",
    "from utils.common_config import get_train_dataset, get_transformations,\\\n",
    "                                get_val_dataset, get_train_dataloader, get_val_dataloader,\\\n",
    "                                get_optimizer, get_model, adjust_learning_rate,\\\n",
    "                                get_criterion\n",
    "from utils.logger import Logger\n",
    "from train.train_utils import train_vanilla\n",
    "from evaluation.evaluate_utils import eval_model, validate_results, save_model_predictions,\\\n",
    "                                    eval_all_results\n",
    "from termcolor import colored\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "config_env = './configs/env.yml'\n",
    "config_exp1 = './configs/nyud/hrnet18/mti_net+edges_normals.yml'\n",
    "config_exp2 = 'C:/Users/ataka/PycharmProjects/CMP712/configs/pascal/hrnet18/mti_net.yml'\n",
    "image_path = \"/home/atakan/Thesis/TensorRT/test_data/\"\n",
    "print(\"import files handled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f747fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_my_model(p, test_data, model):\n",
    "    tasks = p.TASKS.NAMES\n",
    "    print(colored(\"Tasks are:\", 'blue'), colored(tasks, 'red'))\n",
    "    #performance_meter = PerformanceMeter(p)\n",
    "    print(\"Burada performance meter sadece bilgilendirme amaçlı tutuluyor. Inference time incelenecek.\")\n",
    "\n",
    "    model.eval() #activate eval mode to test.\n",
    "    images = test_data # Test data must be an image in the form of \n",
    "                       # img[1, 3 , 480, 640] # [N, C, H, W]\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    with torch.no_grad():\n",
    "        start.record()\n",
    "        output = model(images)\n",
    "        end.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        print(start.elapsed_time(end))\n",
    "    return output\n",
    "\n",
    "def load_test_data(image_name):\n",
    "    image = PIL.Image.open(image_path + image_name)\n",
    "    print (image_name,\" görüntüsünün boyutları: \", image.size)\n",
    "    print (\"Test için boyutları ayarlanıyor. \") # NYUD icin H = 480, W = 640\n",
    "    size = (640, 480) # W = 640, H = 480\n",
    "    image = image.resize(size)\n",
    "    print (\"Yüklenen goruntunun yeni boyutları: \", image.size)\n",
    "    return image\n",
    "\n",
    "def convert_data(image):\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    tensor_image = transform(image)\n",
    "    return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa22680",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(mode=True)\n",
    "cv2.setNumThreads(0)\n",
    "#p = create_config(args.config_env, args.config_exp) orjinal hali\n",
    "p = create_config(config_env, config_exp1)\n",
    "sys.stdout = Logger(os.path.join(p['output_dir'], 'log_file.txt'))\n",
    "print(colored(p, 'red'))\n",
    "print(torch.cuda.is_available())\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c68bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get model\n",
    "print(colored('Retrieve model', 'blue'))\n",
    "model = get_model(p)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model = model.cuda()\n",
    "print(model)\n",
    "model1 = model\n",
    "if model1 == model:\n",
    "    print(\"Yes they are equal ! Keep going bro!\")\n",
    "else:\n",
    "    print(\"You failed f*cking idiot\")\n",
    "#Now load pre trained weights\n",
    "model.load_state_dict(torch.load(p['checkpoint'])['model'])\n",
    "\n",
    "print(\"p[train_db_name] :\", p['train_db_name']);\n",
    "print(\"trBatch size is: \", p['trBatch'])\n",
    "print(\"valBatch size is\", p['valBatch'])\n",
    "\n",
    "test_image = load_test_data(\"yatak_odasi.jpg\")\n",
    "test_tensor_image = convert_data(test_image)\n",
    "test_tensor_image = test_tensor_image.unsqueeze(0)\n",
    "print(\"Type of test_tensor_image:\", type(test_tensor_image))\n",
    "print(\"Shape of test_tensor_image:\", test_tensor_image.size())\n",
    "\n",
    "out = eval_my_model(p, test_tensor_image, model)\n",
    "#print(out)\n",
    "print(\"Type of out image: \", type(out))\n",
    "#print(\"Shape of out image:\", out.size())\n",
    "for key, value in out.items():\n",
    "    print (key)\n",
    "\n",
    "#print(out['semseg'])\n",
    "print(\"Type of out[semseg] is: \", type(out['semseg']))\n",
    "print(\"Shape of out[semseg] is:\", out['semseg'].size())\n",
    "im = out['semseg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8891d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95525b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Retrieve config file\n",
    "    # initialize a model with the same architecture as the model which parameters you saved into the .pt/h file\n",
    "\n",
    "\n",
    "    # load the parameters into the model\n",
    "\n",
    "\n",
    "\n",
    "    #im = PIL.Image.open(\"C:/Users/ataka/PycharmProjects/CMP712/databases/PASCAL_MT/semseg/pascal-context/2008_000016.png\")\n",
    "    #im.show()\n",
    "    #image = np.array(im)\n",
    "    #from matplotlib import pyplot as plt\n",
    "    #plt.imshow(image, interpolation='nearest')\n",
    "    #plt.show()\n",
    "    #print(np.unique(image))\n",
    "    torch.autograd.set_detect_anomaly(mode=True)\n",
    "    cv2.setNumThreads(0)\n",
    "    #p = create_config(args.config_env, args.config_exp) orjinal hali\n",
    "    p = create_config(config_env, config_exp1)\n",
    "    sys.stdout = Logger(os.path.join(p['output_dir'], 'log_file.txt'))\n",
    "    print(colored(p, 'red'))\n",
    "    print(torch.cuda.is_available())\n",
    "\n",
    "    # Get model\n",
    "    print(colored('Retrieve model', 'blue'))\n",
    "    model = get_model(p)\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model = model.cuda()\n",
    "    print(model)\n",
    "    model1 = model\n",
    "    if model1 == model:\n",
    "        print(\"Yes they are equal ! Keep going bro!\")\n",
    "    else:\n",
    "        print(\"You failed f*cking idiot\")\n",
    "    #Now load pre trained weights\n",
    "    model.load_state_dict(torch.load(p['checkpoint'])['model'])\n",
    "\n",
    "    print(\"p[train_db_name] :\", p['train_db_name']);\n",
    "    print(\"trBatch size is: \", p['trBatch'])\n",
    "    print(\"valBatch size is\", p['valBatch'])\n",
    "\n",
    "    test_image = load_test_data(\"yatak_odasi.jpg\")\n",
    "    test_tensor_image = convert_data(test_image)\n",
    "    test_tensor_image = test_tensor_image.unsqueeze(0)\n",
    "    print(\"Type of test_tensor_image:\", type(test_tensor_image))\n",
    "    print(\"Shape of test_tensor_image:\", test_tensor_image.size())\n",
    "\n",
    "    out = eval_my_model(p, test_tensor_image, model)\n",
    "    #print(out)\n",
    "    print(\"Type of out image: \", type(out))\n",
    "    #print(\"Shape of out image:\", out.size())\n",
    "    for key, value in out.items():\n",
    "        print (key)\n",
    "\n",
    "    #print(out['semseg'])\n",
    "    print(\"Type of out[semseg] is: \", type(out['semseg']))\n",
    "    print(\"Shape of out[semseg] is:\", out['semseg'].size())\n",
    "    im = out['semseg']\n",
    "    #plt.imshow(im.permute(2, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7562b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "    # Get criterion\n",
    "    print(colored('Get loss', 'blue'))\n",
    "    criterion = get_criterion(p)\n",
    "    criterion.cuda()\n",
    "    print(criterion)\n",
    "\n",
    "    # CUDNN\n",
    "    print(colored('Set CuDNN benchmark', 'blue')) \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # Optimizer\n",
    "    print(colored('Retrieve optimizer', 'blue'))\n",
    "    optimizer = get_optimizer(p, model)\n",
    "    print(optimizer)\n",
    "\n",
    "    # Dataset\n",
    "    print(colored('Retrieve dataset', 'blue'))\n",
    "    # Transforms\n",
    "    train_transforms, val_transforms = get_transformations(p)\n",
    "    train_dataset = get_train_dataset(p, train_transforms)\n",
    "    print(train_dataset)\n",
    "    from PIL import Image\n",
    "    im = Image.open(train_dataset.images[4])\n",
    "    im.show()\n",
    "    _im = np.array(im).astype(np.float32)\n",
    "    print(_im)\n",
    "    print(\"Type and shape of image:\", type(_im), _im.shape)\n",
    "    val_dataset = get_val_dataset(p, val_transforms)\n",
    "    true_val_dataset = get_val_dataset(p, None) # True validation dataset without reshape\n",
    "    train_dataloader = get_train_dataloader(p, train_dataset)\n",
    "\n",
    "    val_dataloader = get_val_dataloader(p, val_dataset)\n",
    "    print('Train samples %d - Val samples %d' %(len(train_dataset), len(val_dataset)))\n",
    "    print('Train transformations:')\n",
    "    print(train_transforms)\n",
    "    print('Val transformations:')\n",
    "    print(val_transforms)\n",
    "\n",
    "    # Resume from checkpoint\n",
    "    if os.path.exists(p['checkpoint']):\n",
    "        print(colored('Restart from checkpoint {}'.format(p['checkpoint']), 'blue'))\n",
    "        checkpoint = torch.load(p['checkpoint'], map_location='cpu')\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_result = checkpoint['best_result']\n",
    "        print (\"############################################\")\n",
    "        for i in range(0,5):\n",
    "            print(\"I AM NOT RETRAINED !!!!\")\n",
    "        print (\"############################################\")\n",
    "\n",
    "    else:\n",
    "        print(colored(\"########### I am heree!!!!!!!!!!\"), 'red')\n",
    "        print(colored('No checkpoint file at {}'.format(p['checkpoint']), 'blue'))\n",
    "        start_epoch = 0\n",
    "        save_model_predictions(p, val_dataloader, model)\n",
    "        best_result = eval_all_results(p)\n",
    "\n",
    "\n",
    "    #start_epoch = 0 #Eğer kaydedilen modelin son epochdan sonra devam etmesi isteniyorsa bunun\n",
    "                    # yorum olarak kalması gerekir.\n",
    "    # Main loop\n",
    "    print(colored('Starting main loop', 'blue'))\n",
    "\n",
    "    for epoch in range(start_epoch, p['epochs']):\n",
    "        print(colored('Epoch %d/%d' %(epoch+1, p['epochs']), 'yellow'))\n",
    "        print(colored('-'*10, 'yellow'))\n",
    "\n",
    "        # Adjust lr\n",
    "        lr = adjust_learning_rate(p, optimizer, epoch)\n",
    "        print('Adjusted learning rate to {:.5f}'.format(lr))\n",
    "\n",
    "        # Train \n",
    "        print('Train ...')\n",
    "        eval_train = train_vanilla(p, train_dataloader, model, criterion, optimizer, epoch)\n",
    "\n",
    "        # Evaluate\n",
    "            # Check if need to perform eval first\n",
    "        if 'eval_final_10_epochs_only' in p.keys() and p['eval_final_10_epochs_only']: # To speed up -> Avoid eval every epoch, and only test during final 10 epochs.\n",
    "            if epoch + 1 > p['epochs'] - 10:\n",
    "                eval_bool = True\n",
    "            else:\n",
    "                eval_bool = False\n",
    "        else:\n",
    "            eval_bool = True\n",
    "\n",
    "        # Perform evaluation\n",
    "        if eval_bool:\n",
    "            print('Evaluate ...')\n",
    "            save_model_predictions(p, val_dataloader, model)\n",
    "            curr_result = eval_all_results(p)\n",
    "            improves, best_result = validate_results(p, curr_result, best_result)\n",
    "            if improves:\n",
    "                print('Save new best model')\n",
    "                torch.save(model.state_dict(), p['best_model'])\n",
    "\n",
    "        # Checkpoint\n",
    "        print('Checkpoint ...')\n",
    "        torch.save({'optimizer': optimizer.state_dict(), 'model': model.state_dict(), \n",
    "                    'epoch': epoch + 1, 'best_result': best_result}, p['checkpoint'])\n",
    "\n",
    "    # Evaluate best model at the end\n",
    "    print(colored('Evaluating best model at the end', 'blue'))\n",
    "    model.load_state_dict(torch.load(p['checkpoint'])['model']) #this must be p['best_result']\n",
    "    save_model_predictions(p, val_dataloader, model)\n",
    "    eval_stats = eval_all_results(p)\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
